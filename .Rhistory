knitr::opts_chunk$set(echo = FALSE)
library(tidyverse) #to clean and perp data
library(tidymodels) # to access some of the tidy model tools
library(janitor) # to clean data
library(tidyverse) #to clean and perp data
library(tidymodels) # to access some of the tidy model tools
library(janitor) # to clean data
library(tidyverse) #to clean and perp data
library(tidymodels) # to access some of the tidy model tools
library(janitor) # to clean data
library(tidyverse) #to clean and perp data
library(tidymodels) # to access some of the tidy model tools
library(janitor) # to clean data
folder_url <- "https://drive.google.com/drive/folders/1am3wIQPXFvvFAmsJG2m85HLl0G63rJE4?usp=sharing"
folder <- drive_get(as_id(folder_url))
folder_url <- "https://drive.google.com/drive/folders/1am3wIQPXFvvFAmsJG2m85HLl0G63rJE4?usp=sharing"
folder <- drive_dowload(as_id(folder_url))
folder <- drive_download(as_id(folder_url))
folder <- drive_download(as_id(folder_url))
install.packages("googledrive")
folder <- drive_download(as_id(folder_url))
library(tidyverse) #to clean and perp data
library(tidymodels) # to access some of the tidy model tools
library(janitor) # to clean data
library(googledrive) #to get files from google drive
folder <- drive_download(as_id(folder_url))
folder <- drive_get(as_id(folder_url))
csv_files <- drive_ls(folder, type = "csv")
walk(csv_files$id, ~ drive_download(as_id(.x)))
sensor_list <- list.files()
sensor_list <- list.files(pattern=”*.csv”)
sensor_list
sensor_list <- list.files(pattern=*.csv”)
sensor_list <- list.files(pattern=*.csv)
sensor_list <- list.files(pattern="*.csv")
sensor_list <- list.files(pattern="*.csv")
sensor_list
?fread
SD <- bind_rows(lapply(sensor_list,fread))
SD <- sensor_list %>% map(read_csv) %>% reduce(rbind)
View(SD)
SD
SD1 <- SD %>% filter(time>=1)
SD1
sensor_list <- list.files(pattern="*.csv")#creating a list of sensor files
SD <- sensor_list %>% map(read_csv) %>% reduce(rbind) #combine all files
SD1 <- SD %>% filter(time<=1)
?map_drf
SD <- sensor_list %>% map_dfr(read_csv, .id = "/") %>% group_by(/) %>% mutate(ID=group_indices()) #combine all files
WD <- getwd()#get working directory to combine files
SD <- sensor_list %>% map_dfr(read_csv, .id = WD) %>% group_by(WD) %>% mutate(ID=group_indices()) #combine all files
SD <- sensor_list %>% map_dfr(read_csv, .id = "WD") %>% group_by(WD) %>% mutate(ID=group_indices()) #combine all files
SD <- sensor_list %>% map_dfr(read_csv, .id = "WD") %>% group_by(WD) %>% mutate(ID=cur_group_id()) #combine all files
SD
View(SD)
View(SD)
SD1 <- SD %>% filter(time<=1)
View(SD1)
View(SD1)
sensor_list <- list.files(pattern="*.csv")#creating a list of sensor files
WD <- getwd()#get working directory to combine files
SD <- sensor_list %>% map_dfr(read_csv, .id = "WD") %>% group_by(WD) %>% mutate(ID=cur_group_id()) #combine all files
SD1 <- SD %>% filter(time<=60)#filtering out all data above the minute mark
View(SD1)
View(SD1)
View(SD1)
View(SD1)
sensor_list <- list.files(pattern="*.csv")#creating a list of sensor files
FP <- getwd()#get working directory to combine files
SD <- sensor_list %>% map_dfr(read_csv, .id = "WD") %>% group_by(WD) %>% mutate(id=cur_group_id()) #combine all files
SD1 <- SD %>% filter(time<=60)#filtering out all data above the minute mark (60 seconds)
View(SD)
View(SD)
sensor_list <- list.files(pattern="*.csv")#creating a list of sensor files
FP <- getwd()#get working directory to combine files
SD <- sensor_list %>% map_dfr(read_csv, .id = "WD") %>% group_by(WD) %>% mutate(id=cur_group_id()) %>% select(-WD) #combine all files
SD1 <- SD %>% filter(time<=60)#filtering out all data above the minute mark (60 seconds)
sensor_list <- list.files(pattern="*.csv")#creating a list of sensor files
FP <- getwd()#get working directory to combine files
SD <- sensor_list %>% map_dfr(read_csv, .id = "WD") %>% group_by(WD) %>% mutate(id=cur_group_id()) #combine all files
SD1 <- SD %>% filter(time<=60)#filtering out all data above the minute mark (60 seconds)
View(SD1)
View(SD1)
sensor_list <- list.files(pattern="*.csv")#creating a list of sensor files
FP <- getwd()#get working directory to combine files
SD <- sensor_list %>% map_dfr(read_csv, .id = "FP") %>% group_by(WD) %>% mutate(id=cur_group_id()) #combine all files
sensor_list <- list.files(pattern="*.csv")#creating a list of sensor files
WD <- getwd()#get working directory to combine files
SD <- sensor_list %>% map_dfr(read_csv, .id = "WD") %>% group_by(WD) %>% mutate(id=cur_group_id()) #combine all files
SD1 <- SD %>% filter(time<=60)#filtering out all data above the minute mark (60 seconds)
View(SD1)
library(tidyverse) #to clean and prep data
library(tidymodels) # to access some of the tidy model tools
library(janitor) # to clean data
library(googledrive)#to get files from Google drive
library(broom)
Kmeans <- kmeans(SD1, 3)
sensor_list <- list.files(pattern="*.csv")#creating a list of sensor files
WD <- getwd()#get working directory to combine files
SD <- sensor_list %>% map(read_csv) %>% group_by(WD) %>% mutate(id=cur_group_id()) #combine all files
sensor_list <- list.files(pattern="*.csv")#creating a list of sensor files
WD <- getwd()#get working directory to combine files
SD <- sensor_list %>% map_dfr(read_csv, .id = "WD") %>% group_by(WD) %>% mutate(id=cur_group_id()) #combine all files
SD1 <- SD %>% filter(time<=60)#filtering out all data above the minute mark (60 seconds)
View(Kmeans)
View(Kmeans)
p1 <-
ggplot(augment(Kmeans), aes(x = x1, y = x2)) +
geom_point(aes(color = .cluster), alpha = 0.8) +
facet_wrap(~ k)
p1 <-
ggplot(augment(Kmeans), aes(x = x1, y = x2)) +
geom_point(aes(color = .cluster), alpha = 0.8)
Clust <- augment(Kmeans)
p1 <-
ggplot(Kmeans, aes(x = x1, y = x2)) +
geom_point(aes(color = .cluster), alpha = 0.8)
p1 <-
ggplot(Clust, aes(x = x1, y = x2)) +
geom_point(aes(color = .cluster), alpha = 0.8)
Clust <- augment(Kmeans)
Clust <- augment(Kmeans)
Clust <- augment(Kmeans,SD1)
p1 <-
ggplot(Clust, aes(x = x1, y = x2)) +
geom_point(aes(color = .cluster), alpha = 0.8)
Kmeans <- kmeans(SD1, 3)
Clust <- augment(Kmeans,SD1)
p1 <-
ggplot(Clust, aes(x = x1, y = x2)) +
geom_point(aes(color = .cluster), alpha = 0.8)
p1
View(p1)
View(p1)
Clust
p1 <-
ggplot(Clust, aes(x = wx, y = wx, z=wz)) +
geom_point(aes(color = .cluster), alpha = 0.8)
p1
p1 <-
ggplot(Clust, aes(x = wx, y = wz)) +
geom_point(aes(color = .cluster), alpha = 0.8)
p1
p1 <-
ggplot(Clust, aes(x = wy, y = wz)) +
geom_point(aes(color = .cluster), alpha = 0.8)
p1
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse) #to clean and prep data
library(tidymodels) # to access some of the tidy model tools
library(janitor) # to clean data
library(googledrive)#to get files from Google drive
library(broom)
#using google drive to download files from Google Drive
folder_url <- "https://drive.google.com/drive/folders/1am3wIQPXFvvFAmsJG2m85HLl0G63rJE4?usp=sharing" #folder that contains the csv files
folder <- drive_get(as_id(folder_url))
csv_files <- drive_ls(folder, type = "csv")
walk(csv_files$id, ~ drive_download(as_id(.x)))
Kmeans <- kmeans(SD1, 5)
Clust <- augment(Kmeans,SD1)
p1 <-
ggplot(Clust, aes(x = wy, y = wz)) +
geom_point(aes(color = .cluster), alpha = 0.8)
p1
Kmeans <- kmeans(SD1, 5)
Clust <- augment(Kmeans,SD1)
p1 <-
ggplot(Clust, aes(x = wx, y = wz)) +
geom_point(aes(color = .cluster), alpha = 0.8)
p1
p1 <-
ggplot(Clust, aes(x = wx, y = wy)) +
geom_point(aes(color = .cluster), alpha = 0.5)
p1
rm(ls())
ls(0)
ls()
rm(list=ls())
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse) #to clean and prep data
library(tidymodels) # to access some of the tidy model tools
library(janitor) # to clean data
library(googledrive)#to get files from Google drive
library(broom)
#using google drive to download files from Google Drive
folder_url <- "https://drive.google.com/drive/folders/1am3wIQPXFvvFAmsJG2m85HLl0G63rJE4?usp=sharing" #folder that contains the csv files
folder <- drive_get(as_id(folder_url))
csv_files <- drive_ls(folder, type = "csv")
walk(csv_files$id, ~ drive_download(as_id(.x)))
#using google drive to download files from Google Drive
folder_url <- "https://drive.google.com/drive/folders/1am3wIQPXFvvFAmsJG2m85HLl0G63rJE4?usp=sharing" #folder that contains the csv files
folder <- drive_get(as_id(folder_url))
csv_files <- drive_ls(folder, type = "csv")
walk(csv_files$id, ~ drive_download(as_id(.x)))
#using google drive to download files from Google Drive
folder_url <- "https://drive.google.com/drive/folders/1am3wIQPXFvvFAmsJG2m85HLl0G63rJE4?usp=sharing" #folder that contains the csv files
folder <- drive_get(as_id(folder_url))
csv_files <- drive_ls(folder, type = "csv")
walk(csv_files$id, ~ drive_download(as_id(.x), overwrite = FALSE))
View(folder)
View(folder)
View(folder[[3]][[1]])
sensor_list <- list.files(pattern="*.csv")#creating a list of sensor files
WD <- getwd()#get working directory to combine files
SD <- sensor_list %>% map_dfr(read_csv, .id = "WD") %>% group_by(WD) %>% mutate(id=cur_group_id()) #combine all files
sensor_list <- list.files(pattern="*.csv")#creating a list of sensor files
WD <- getwd()#get working directory to combine files
SD <- sensor_list %>% map_dfr(read_csv, .id = "WD") %>% group_by(WD) %>% mutate(id=cur_group_id()) #combine all files
SD1 <- SD %>% filter(time<=60)#filtering out all data above the minute mark (60 seconds)
View(SD)
View(SD)
sensor_list <- list.files(pattern="*.csv")#creating a list of sensor files
WD <- getwd()#get working directory to combine files
SD <- sensor_list %>% map_dfr(read_csv, .id = "WD") %>% group_by(WD) %>% mutate(id=cur_group_id()) #combine all files
SD1 <- SD %>%select(3:5) %>% filter(time<=60)#filtering out all data above the minute mark (60 seconds)
hist(SD$wz)
hist(SD$wy)
hist(SD$wx)
sensor_list <- list.files(pattern="*.csv")#creating a list of sensor files
WD <- getwd()#get working directory to combine files
SD <- sensor_list %>% map_dfr(read_csv, .id = "WD") %>% group_by(WD) %>% mutate(id=cur_group_id()) #combine all files
SD1 <- SD %>% filter(time<=60) %>% select(3:5) #filtering out all data above the minute mark (60 seconds)
View(SD1)
SD <- sensor_list %>% map_dfr(read_csv) %>% group_by(WD) %>% mutate(id=cur_group_id()) #combine all files
View(SD)
rm(SD)
SD <- sensor_list %>% map_dfr(read_csv) %>% group_by(WD) %>% mutate(id=cur_group_id()) #combine all files
sensor_list <- list.files(pattern="*.csv")#creating a list of sensor files
WD <- getwd()#get working directory to combine files
SD <- sensor_list %>% map_dfr(read_csv,.id = "WD") %>% group_by(WD) %>% mutate(id=cur_group_id()) #combine all files
SD1 <- SD %>% filter(time<=60)  #filtering out all data above the minute mark (60 seconds)
View(SD1)
View(SD1)
SD2 <- SD1 %>% select(-1,-2,-6)
View(SD2)
View(SD2)
rm(SD2)
SD1 <- SD %>% filter(time<=60) %>% ungroup() %>% select(3:5) #filtering out all data above the minute mark (60 seconds)
View(SD1)
Kmeans <- kmeans(SD1, 5)
Clust <- augment(Kmeans,SD1)
p1 <-
ggplot(Clust, aes(x = wx, y = wy)) +
geom_point(aes(color = .cluster), alpha = 0.5)
p1
Kmeans <- kmeans(SD1, 5)
Clust <- augment(Kmeans,SD1)
p1 <-
ggplot(Clust, aes(x = wx, y = wz)) +
geom_point(aes(color = .cluster), alpha = 0.5)
p1
Kmeans <- kmeans(SD1, 3)
Clust <- augment(Kmeans,SD1)
p1 <-
ggplot(Clust, aes(x = wx, y = wz)) +
geom_point(aes(color = .cluster), alpha = 0.5)
p1
Kmeans <- kmeans(SD1, 5)
Clust <- augment(Kmeans,SD1)
p1 <-
ggplot(Clust, aes(x = wx, y = wz)) +
geom_point(aes(color = .cluster), alpha = 0.5)
p1
Kmeans <- kmeans(SD1, 6)
Clust <- augment(Kmeans,SD1)
p1 <-
ggplot(Clust, aes(x = wx, y = wz)) +
geom_point(aes(color = .cluster), alpha = 0.5)
p1
Kmeans <- kmeans(SD1, 3)
Clust <- augment(Kmeans,SD1)
p1 <-
ggplot(Clust, aes(x = wx, y = wz)) +
geom_point(aes(color = .cluster), alpha = 0.5)
p1
Kmeans <- kmeans(SD1, 3)
Clust <- augment(Kmeans,SD1)
p1 <-
ggplot(Clust, aes(x = wx, y = wy)) +
geom_point(aes(color = .cluster), alpha = 0.5)
p1
Kmeans <- kmeans(SD1, 4)
Clust <- augment(Kmeans,SD1)
p1 <-
ggplot(Clust, aes(x = wx, y = wy)) +
geom_point(aes(color = .cluster), alpha = 0.5)
p1
?princomp
sensor_list <- list.files(pattern="*.csv")#creating a list of sensor files
WD <- getwd()#get working directory to combine files
SD <- sensor_list %>% map_dfr(read_csv,.id = "WD") %>% group_by(WD) %>% mutate(id=cur_group_id()) #combine all files
SD1 <- SD %>% filter(time<=60) %>% ungroup() %>% select(2:5) #filtering out all data above the minute mark (60 seconds)
View(SD1)
Kmeans <- kmeans(SD1, 4)
Clust <- augment(Kmeans,SD1)
View(Clust)
p1 <-
ggplot(Clust, aes(x = time, y = wx)) +
geom_point(aes(color = .cluster), alpha = 0.5)
p1
p1 <-
ggplot(Clust, aes(x = wx, y = time)) +
geom_point(aes(color = .cluster), alpha = 0.5)
p1
Kmeans <- kmeans(SD1, 4)
Clust <- augment(Kmeans,SD1)
p1 <-
ggplot(Clust, aes(x = wx, y =wy)) +
geom_point(aes(color = .cluster), alpha = 0.5)
p1
PCA <- princomp(SD1, scale.=TRUE)
summary(PCA)
loadings <- abs(pca$rotation)
loadings <- abs(PCA$rotation)
PCA$rotations
View(PCA)
PCA$loadings
PCA <- princomp(SD1, scale.=TRUE)
summary(PCA)
PCA$loadings
sensor_list <- list.files(pattern="*.csv")#creating a list of sensor files
WD <- getwd()#get working directory to combine files
SD <- sensor_list %>% map_dfr(read_csv,.id = "WD") %>% group_by(WD) %>% mutate(id=cur_group_id()) #combine all files
SD1 <- SD %>% filter(time<=60) %>% ungroup() %>% select(3:5) #filtering out all data above the minute mark (60 seconds)
PCA <- princomp(SD1, scale.=TRUE)
summary(PCA)
PCA$loadings
SD2 <- augment(PCA,data=SD)
library(broom)
SD2 <- augment(PCA,data=SD)
PCA <- prcomp(SD1, scale.=TRUE)
summary(PCA)
View(PCA)
View(PCA)
PCA$rotations
PCA$rotation
library(broom)
PCA <- prcomp(SD1, scale.=TRUE)
summary(PCA)
PCA$rotation
SD2 <- augment(PCA,data=SD)
SD2 <- augment(PCA,data=SD1)
library(broom)
PCA <- prcomp(SD1, scale.=TRUE)
summary(PCA)
PCA$rotation
SD2 <- augment(PCA,data=SD1)
View(SD2)
View(SD2)
Kmeans <- kmeans(SD2, 3)
Clust <- augment(Kmeans,SD2)
View(Clust)
View(Clust)
p1 <-
ggplot(Clust, aes(x =.fittedPC1 , y =.fittedPC2)) +
geom_point(aes(color = .cluster), alpha = 0.5)
p1
SD3 <- SD2 %>% select(5:6)
Kmeans <- kmeans(SD3, 3)
Clust <- augment(Kmeans,SD3)
p1 <-
ggplot(Clust, aes(x =.fittedPC1 , y =.fittedPC2)) +
geom_point(aes(color = .cluster), alpha = 0.5)
p1
View(SD3)
View(SD3)
View(SD)
View(SD)
biplot(SD2)
biplot(PCA)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) #to clean and prep data
library(tidymodels) # to access some of the tidy model tools
library(janitor) # to clean data
library(googledrive)#to get files from Google drive
library(broom)#to extract the PCs and Clusters
sensor_list <- list.files(pattern="*.csv")#creating a list of sensor files
WD <- getwd()#get working directory to combine files
SK <- sensor_list %>% map_dfr(read_csv,.id = "WD") %>% group_by(WD) %>% mutate(id=cur_group_id()) %>% filter(time<=60) #combine all files and filter anything under a minute or 60s
View(SK)
View(SK)
View(SK)
View(SK)
View(SD)
View(SD)
View(SD)
View(SD)
View(SD)
DF <- SD %>% ungroup() %>% select(2:6)#combine all files and filter anything under a minute or 60s
View(DF)
View(DF)
DF1 <- DF %>% as.character(time)
DF$time= as.character(DF$time)
library(tidyverse) #to clean and prep data
library(tidymodels) # to access some of the tidy model tools
library(janitor) # to clean data
library(googledrive)#to get files from Google drive
library(broom)#to extract the PCs and Clusters
DF1 <- DF %>% pivot_wider(names_from = time, values_from = c(wx,wy,wz))
View(DF1)
DF1
View(DF1)
View(SD)
View(SD)
hist(SD$id)
hist(SD$time)
DF <- SD %>% ungroup() %>% select(2:6) %>% mutate(time=round(time,3))
View(DF)
DF
DF$time= as.character(DF$time)
DF1 <- DF %>% pivot_wider(names_from = time, values_from = c(wx,wy,wz))
DF1
View(DF1)
DF <- SD %>% ungroup() %>% select(2:6) %>% mutate(time=round(time,2))
View(DF)
DF <- SD %>% ungroup() %>% select(2:6) %>% mutate(time=round(time,2))
DF <- SD %>% ungroup() %>% select(2:6) %>% mutate(time=round(time,2)) %>% distinct()
DF$time= as.character(DF$time)
DF1 <- DF %>% pivot_wider(names_from = time, values_from = c(wx,wy,wz))
View(DF)
View(DF)
View(DF1)
