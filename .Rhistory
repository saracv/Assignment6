sensor_list <- list.files(pattern="*.csv")#creating a list of sensor files
FP <- getwd()#get working directory to combine files
SD <- sensor_list %>% map_dfr(read_csv, .id = "WD") %>% group_by(WD) %>% mutate(id=cur_group_id()) #combine all files
SD1 <- SD %>% filter(time<=60)#filtering out all data above the minute mark (60 seconds)
View(SD1)
View(SD1)
sensor_list <- list.files(pattern="*.csv")#creating a list of sensor files
FP <- getwd()#get working directory to combine files
SD <- sensor_list %>% map_dfr(read_csv, .id = "FP") %>% group_by(WD) %>% mutate(id=cur_group_id()) #combine all files
sensor_list <- list.files(pattern="*.csv")#creating a list of sensor files
WD <- getwd()#get working directory to combine files
SD <- sensor_list %>% map_dfr(read_csv, .id = "WD") %>% group_by(WD) %>% mutate(id=cur_group_id()) #combine all files
SD1 <- SD %>% filter(time<=60)#filtering out all data above the minute mark (60 seconds)
View(SD1)
library(tidyverse) #to clean and prep data
library(tidymodels) # to access some of the tidy model tools
library(janitor) # to clean data
library(googledrive)#to get files from Google drive
library(broom)
Kmeans <- kmeans(SD1, 3)
sensor_list <- list.files(pattern="*.csv")#creating a list of sensor files
WD <- getwd()#get working directory to combine files
SD <- sensor_list %>% map(read_csv) %>% group_by(WD) %>% mutate(id=cur_group_id()) #combine all files
sensor_list <- list.files(pattern="*.csv")#creating a list of sensor files
WD <- getwd()#get working directory to combine files
SD <- sensor_list %>% map_dfr(read_csv, .id = "WD") %>% group_by(WD) %>% mutate(id=cur_group_id()) #combine all files
SD1 <- SD %>% filter(time<=60)#filtering out all data above the minute mark (60 seconds)
View(Kmeans)
View(Kmeans)
p1 <-
ggplot(augment(Kmeans), aes(x = x1, y = x2)) +
geom_point(aes(color = .cluster), alpha = 0.8) +
facet_wrap(~ k)
p1 <-
ggplot(augment(Kmeans), aes(x = x1, y = x2)) +
geom_point(aes(color = .cluster), alpha = 0.8)
Clust <- augment(Kmeans)
p1 <-
ggplot(Kmeans, aes(x = x1, y = x2)) +
geom_point(aes(color = .cluster), alpha = 0.8)
p1 <-
ggplot(Clust, aes(x = x1, y = x2)) +
geom_point(aes(color = .cluster), alpha = 0.8)
Clust <- augment(Kmeans)
Clust <- augment(Kmeans)
Clust <- augment(Kmeans,SD1)
p1 <-
ggplot(Clust, aes(x = x1, y = x2)) +
geom_point(aes(color = .cluster), alpha = 0.8)
Kmeans <- kmeans(SD1, 3)
Clust <- augment(Kmeans,SD1)
p1 <-
ggplot(Clust, aes(x = x1, y = x2)) +
geom_point(aes(color = .cluster), alpha = 0.8)
p1
View(p1)
View(p1)
Clust
p1 <-
ggplot(Clust, aes(x = wx, y = wx, z=wz)) +
geom_point(aes(color = .cluster), alpha = 0.8)
p1
p1 <-
ggplot(Clust, aes(x = wx, y = wz)) +
geom_point(aes(color = .cluster), alpha = 0.8)
p1
p1 <-
ggplot(Clust, aes(x = wy, y = wz)) +
geom_point(aes(color = .cluster), alpha = 0.8)
p1
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse) #to clean and prep data
library(tidymodels) # to access some of the tidy model tools
library(janitor) # to clean data
library(googledrive)#to get files from Google drive
library(broom)
#using google drive to download files from Google Drive
folder_url <- "https://drive.google.com/drive/folders/1am3wIQPXFvvFAmsJG2m85HLl0G63rJE4?usp=sharing" #folder that contains the csv files
folder <- drive_get(as_id(folder_url))
csv_files <- drive_ls(folder, type = "csv")
walk(csv_files$id, ~ drive_download(as_id(.x)))
Kmeans <- kmeans(SD1, 5)
Clust <- augment(Kmeans,SD1)
p1 <-
ggplot(Clust, aes(x = wy, y = wz)) +
geom_point(aes(color = .cluster), alpha = 0.8)
p1
Kmeans <- kmeans(SD1, 5)
Clust <- augment(Kmeans,SD1)
p1 <-
ggplot(Clust, aes(x = wx, y = wz)) +
geom_point(aes(color = .cluster), alpha = 0.8)
p1
p1 <-
ggplot(Clust, aes(x = wx, y = wy)) +
geom_point(aes(color = .cluster), alpha = 0.5)
p1
rm(ls())
ls(0)
ls()
rm(list=ls())
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse) #to clean and prep data
library(tidymodels) # to access some of the tidy model tools
library(janitor) # to clean data
library(googledrive)#to get files from Google drive
library(broom)
#using google drive to download files from Google Drive
folder_url <- "https://drive.google.com/drive/folders/1am3wIQPXFvvFAmsJG2m85HLl0G63rJE4?usp=sharing" #folder that contains the csv files
folder <- drive_get(as_id(folder_url))
csv_files <- drive_ls(folder, type = "csv")
walk(csv_files$id, ~ drive_download(as_id(.x)))
#using google drive to download files from Google Drive
folder_url <- "https://drive.google.com/drive/folders/1am3wIQPXFvvFAmsJG2m85HLl0G63rJE4?usp=sharing" #folder that contains the csv files
folder <- drive_get(as_id(folder_url))
csv_files <- drive_ls(folder, type = "csv")
walk(csv_files$id, ~ drive_download(as_id(.x)))
#using google drive to download files from Google Drive
folder_url <- "https://drive.google.com/drive/folders/1am3wIQPXFvvFAmsJG2m85HLl0G63rJE4?usp=sharing" #folder that contains the csv files
folder <- drive_get(as_id(folder_url))
csv_files <- drive_ls(folder, type = "csv")
walk(csv_files$id, ~ drive_download(as_id(.x), overwrite = FALSE))
View(folder)
View(folder)
View(folder[[3]][[1]])
sensor_list <- list.files(pattern="*.csv")#creating a list of sensor files
WD <- getwd()#get working directory to combine files
SD <- sensor_list %>% map_dfr(read_csv, .id = "WD") %>% group_by(WD) %>% mutate(id=cur_group_id()) #combine all files
sensor_list <- list.files(pattern="*.csv")#creating a list of sensor files
WD <- getwd()#get working directory to combine files
SD <- sensor_list %>% map_dfr(read_csv, .id = "WD") %>% group_by(WD) %>% mutate(id=cur_group_id()) #combine all files
SD1 <- SD %>% filter(time<=60)#filtering out all data above the minute mark (60 seconds)
View(SD)
View(SD)
sensor_list <- list.files(pattern="*.csv")#creating a list of sensor files
WD <- getwd()#get working directory to combine files
SD <- sensor_list %>% map_dfr(read_csv, .id = "WD") %>% group_by(WD) %>% mutate(id=cur_group_id()) #combine all files
SD1 <- SD %>%select(3:5) %>% filter(time<=60)#filtering out all data above the minute mark (60 seconds)
hist(SD$wz)
hist(SD$wy)
hist(SD$wx)
sensor_list <- list.files(pattern="*.csv")#creating a list of sensor files
WD <- getwd()#get working directory to combine files
SD <- sensor_list %>% map_dfr(read_csv, .id = "WD") %>% group_by(WD) %>% mutate(id=cur_group_id()) #combine all files
SD1 <- SD %>% filter(time<=60) %>% select(3:5) #filtering out all data above the minute mark (60 seconds)
View(SD1)
SD <- sensor_list %>% map_dfr(read_csv) %>% group_by(WD) %>% mutate(id=cur_group_id()) #combine all files
View(SD)
rm(SD)
SD <- sensor_list %>% map_dfr(read_csv) %>% group_by(WD) %>% mutate(id=cur_group_id()) #combine all files
sensor_list <- list.files(pattern="*.csv")#creating a list of sensor files
WD <- getwd()#get working directory to combine files
SD <- sensor_list %>% map_dfr(read_csv,.id = "WD") %>% group_by(WD) %>% mutate(id=cur_group_id()) #combine all files
SD1 <- SD %>% filter(time<=60)  #filtering out all data above the minute mark (60 seconds)
View(SD1)
View(SD1)
SD2 <- SD1 %>% select(-1,-2,-6)
View(SD2)
View(SD2)
rm(SD2)
SD1 <- SD %>% filter(time<=60) %>% ungroup() %>% select(3:5) #filtering out all data above the minute mark (60 seconds)
View(SD1)
Kmeans <- kmeans(SD1, 5)
Clust <- augment(Kmeans,SD1)
p1 <-
ggplot(Clust, aes(x = wx, y = wy)) +
geom_point(aes(color = .cluster), alpha = 0.5)
p1
Kmeans <- kmeans(SD1, 5)
Clust <- augment(Kmeans,SD1)
p1 <-
ggplot(Clust, aes(x = wx, y = wz)) +
geom_point(aes(color = .cluster), alpha = 0.5)
p1
Kmeans <- kmeans(SD1, 3)
Clust <- augment(Kmeans,SD1)
p1 <-
ggplot(Clust, aes(x = wx, y = wz)) +
geom_point(aes(color = .cluster), alpha = 0.5)
p1
Kmeans <- kmeans(SD1, 5)
Clust <- augment(Kmeans,SD1)
p1 <-
ggplot(Clust, aes(x = wx, y = wz)) +
geom_point(aes(color = .cluster), alpha = 0.5)
p1
Kmeans <- kmeans(SD1, 6)
Clust <- augment(Kmeans,SD1)
p1 <-
ggplot(Clust, aes(x = wx, y = wz)) +
geom_point(aes(color = .cluster), alpha = 0.5)
p1
Kmeans <- kmeans(SD1, 3)
Clust <- augment(Kmeans,SD1)
p1 <-
ggplot(Clust, aes(x = wx, y = wz)) +
geom_point(aes(color = .cluster), alpha = 0.5)
p1
Kmeans <- kmeans(SD1, 3)
Clust <- augment(Kmeans,SD1)
p1 <-
ggplot(Clust, aes(x = wx, y = wy)) +
geom_point(aes(color = .cluster), alpha = 0.5)
p1
Kmeans <- kmeans(SD1, 4)
Clust <- augment(Kmeans,SD1)
p1 <-
ggplot(Clust, aes(x = wx, y = wy)) +
geom_point(aes(color = .cluster), alpha = 0.5)
p1
?princomp
sensor_list <- list.files(pattern="*.csv")#creating a list of sensor files
WD <- getwd()#get working directory to combine files
SD <- sensor_list %>% map_dfr(read_csv,.id = "WD") %>% group_by(WD) %>% mutate(id=cur_group_id()) #combine all files
SD1 <- SD %>% filter(time<=60) %>% ungroup() %>% select(2:5) #filtering out all data above the minute mark (60 seconds)
View(SD1)
Kmeans <- kmeans(SD1, 4)
Clust <- augment(Kmeans,SD1)
View(Clust)
p1 <-
ggplot(Clust, aes(x = time, y = wx)) +
geom_point(aes(color = .cluster), alpha = 0.5)
p1
p1 <-
ggplot(Clust, aes(x = wx, y = time)) +
geom_point(aes(color = .cluster), alpha = 0.5)
p1
Kmeans <- kmeans(SD1, 4)
Clust <- augment(Kmeans,SD1)
p1 <-
ggplot(Clust, aes(x = wx, y =wy)) +
geom_point(aes(color = .cluster), alpha = 0.5)
p1
PCA <- princomp(SD1, scale.=TRUE)
summary(PCA)
loadings <- abs(pca$rotation)
loadings <- abs(PCA$rotation)
PCA$rotations
View(PCA)
PCA$loadings
PCA <- princomp(SD1, scale.=TRUE)
summary(PCA)
PCA$loadings
sensor_list <- list.files(pattern="*.csv")#creating a list of sensor files
WD <- getwd()#get working directory to combine files
SD <- sensor_list %>% map_dfr(read_csv,.id = "WD") %>% group_by(WD) %>% mutate(id=cur_group_id()) #combine all files
SD1 <- SD %>% filter(time<=60) %>% ungroup() %>% select(3:5) #filtering out all data above the minute mark (60 seconds)
PCA <- princomp(SD1, scale.=TRUE)
summary(PCA)
PCA$loadings
SD2 <- augment(PCA,data=SD)
library(broom)
SD2 <- augment(PCA,data=SD)
PCA <- prcomp(SD1, scale.=TRUE)
summary(PCA)
View(PCA)
View(PCA)
PCA$rotations
PCA$rotation
library(broom)
PCA <- prcomp(SD1, scale.=TRUE)
summary(PCA)
PCA$rotation
SD2 <- augment(PCA,data=SD)
SD2 <- augment(PCA,data=SD1)
library(broom)
PCA <- prcomp(SD1, scale.=TRUE)
summary(PCA)
PCA$rotation
SD2 <- augment(PCA,data=SD1)
View(SD2)
View(SD2)
Kmeans <- kmeans(SD2, 3)
Clust <- augment(Kmeans,SD2)
View(Clust)
View(Clust)
p1 <-
ggplot(Clust, aes(x =.fittedPC1 , y =.fittedPC2)) +
geom_point(aes(color = .cluster), alpha = 0.5)
p1
SD3 <- SD2 %>% select(5:6)
Kmeans <- kmeans(SD3, 3)
Clust <- augment(Kmeans,SD3)
p1 <-
ggplot(Clust, aes(x =.fittedPC1 , y =.fittedPC2)) +
geom_point(aes(color = .cluster), alpha = 0.5)
p1
View(SD3)
View(SD3)
View(SD)
View(SD)
biplot(SD2)
biplot(PCA)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) #to clean and prep data
library(tidymodels) # to access some of the tidy model tools
library(janitor) # to clean data
library(googledrive)#to get files from Google drive
library(broom)#to extract the PCs and Clusters
sensor_list <- list.files(pattern="*.csv")#creating a list of sensor files
WD <- getwd()#get working directory to combine files
SK <- sensor_list %>% map_dfr(read_csv,.id = "WD") %>% group_by(WD) %>% mutate(id=cur_group_id()) %>% filter(time<=60) #combine all files and filter anything under a minute or 60s
View(SK)
View(SK)
View(SK)
View(SK)
View(SD)
View(SD)
View(SD)
View(SD)
View(SD)
DF <- SD %>% ungroup() %>% select(2:6)#combine all files and filter anything under a minute or 60s
View(DF)
View(DF)
DF1 <- DF %>% as.character(time)
DF$time= as.character(DF$time)
library(tidyverse) #to clean and prep data
library(tidymodels) # to access some of the tidy model tools
library(janitor) # to clean data
library(googledrive)#to get files from Google drive
library(broom)#to extract the PCs and Clusters
DF1 <- DF %>% pivot_wider(names_from = time, values_from = c(wx,wy,wz))
View(DF1)
DF1
View(DF1)
View(SD)
View(SD)
hist(SD$id)
hist(SD$time)
DF <- SD %>% ungroup() %>% select(2:6) %>% mutate(time=round(time,3))
View(DF)
DF
DF$time= as.character(DF$time)
DF1 <- DF %>% pivot_wider(names_from = time, values_from = c(wx,wy,wz))
DF1
View(DF1)
DF <- SD %>% ungroup() %>% select(2:6) %>% mutate(time=round(time,2))
View(DF)
DF <- SD %>% ungroup() %>% select(2:6) %>% mutate(time=round(time,2))
DF <- SD %>% ungroup() %>% select(2:6) %>% mutate(time=round(time,2)) %>% distinct()
DF$time= as.character(DF$time)
DF1 <- DF %>% pivot_wider(names_from = time, values_from = c(wx,wy,wz))
View(DF)
View(DF)
View(DF1)
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse) #to clean and prep data
library(tidymodels) # to access some of the tidy model tools
library(janitor) # to clean data
library(googledrive)#to get files from Google drive
library(broom)#to extract the PCs and Clusters
library(ggplot2) #to plot
library(GGally)#to plot correlations
sensor_list <- list.files(pattern="*.csv")#creating a list of sensor files
WD <- getwd()#get working directory to combine files
SD <- sensor_list %>% map_dfr(read_csv,.id = "WD") %>% group_by(WD) %>% mutate(id=cur_group_id()) %>% filter(time<=60) #combine all files and filter anything under a minute or 60s
SD1 <- SD %>% summarise(wx=mad(wx),wy=mad(wy),wz=mad(wz)) %>% ungroup()
SD2 <- SD1 %>% select(-1)
PCA <- prcomp(SD2, scale.=TRUE)# run PCA
summary(PCA)#get cumulative Proportion
PCA$rotation #Understand what each component is made up
SD3 <- augment(PCA,data=SD2) #create a frame with all the information
biplot(PCA)
plot(PCA,type="lines")
#From the biplot and the scree plot it makes sense to remove the 3rd components as PC1 and 2 account for more than 99% of the variance.
KT <- SD3 %>% select(5:6)
Kmeans <- kmeans(KT, 4)
Clust <- augment(Kmeans,KT)
p1 <-
ggplot(Clust, aes(x =.fittedPC1 , y =.fittedPC2)) +
geom_point(aes(color = .cluster), alpha = 0.8, size=1.5*(SD1$wx))
p1
Outcomes <- Assignment_6_Outcome_data %>% slice(-8)
library(readxl)
Outcomes <- read_excel("Assignment  6 Outcome data.xlsx")
Taks2_outcomes <- augment(Kmeans,Outcomes)
View(SK)
View(SK)
View(Kmeans)
View(Clust)
View(Outcomes)
Taks2_outcomes <- augment(Kmeans,Outcomes)
View(Kmeans)
View(Kmeans)
View(Taks2_outcomes)
View(Taks2_outcomes)
ggcorr(T2O[,-1,-2], method = c("everything", "pearson"))
T2O <- augment(Kmeans,Outcomes)
View(T2O)
View(T2O)
ggcorr(T2O[,-1,-2], method = c("everything", "pearson"))
View(T2O)
ggcorr(T2O[,-1:2,], method = c("everything", "pearson"))
ggcorr(T2O[,-1:-2,], method = c("everything", "pearson"))
T2O$.cluster=as.numeric(t2O$cluster)
T2O$.cluster=as.numeric(T2O$cluster)
T2O$.cluster=as.numeric(T2O$.cluster)
ggcorr(T2O[,-1:-2,], method = c("everything", "pearson"))
View(Clust)
Outcomes <- read_excel("Assignment  6 Outcome data.xlsx")
T2O <- augment(Clust,Outcomes)
T2O <- augment(Kmeans,Outcomes)
Outcomes <- read_excel("Assignment  6 Outcome data.xlsx")
T2O <- augment(Kmeans,Outcomes)
T2O$.cluster=as.numeric(T2O$.cluster)
ggcorr(T2O[,-1:-2,], method = c("everything", "pearson"))
cor <- cor(T2O[,-1:-2,], method = "pearson" )
cor
cor <- cor(T2O[,-1:-2,], method = "spearman" )
cor
cor <- cor(T2O[,-1:-2,], method = "pearson" )
cor
KT <- SD3 %>% select(5:6)
Kmeans <- kmeans(KT, 3)
Clust <- augment(Kmeans,KT)
p1 <-
ggplot(Clust, aes(x =.fittedPC1 , y =.fittedPC2)) +
geom_point(aes(color = .cluster), alpha = 0.8, size=1.5*(SD1$wx))
p1
Outcomes <- read_excel("Assignment  6 Outcome data.xlsx")
T2O <- augment(Kmeans,Outcomes)
T2O$.cluster=as.numeric(T2O$.cluster)
ggcorr(T2O[,-1:-2,], method = c("everything", "pearson"))
cor <- cor(T2O[,-1:-2,], method = "pearson" )
cor
cor <- cor(T2O[,-1:-2,], method = "pearson" )
cor
View(Clust)
View(Clust)
View(T2O)
View(T2O)
Outcomes <- read_excel("Assignment  6 Outcome data.xlsx")
T2O <- augment(Kmeans,Outcomes)
T2O$.cluster=as.numeric(T2O$.cluster)
ggcorr(T2O[,-1:-2,], method = c("everything", "pearson"))
cor <- cor(T2O[,-1:-2,], method = "spearman" )
cor
Outcomes <- read_excel("Assignment  6 Outcome data.xlsx")
T2O <- augment(Kmeans,Outcomes)
T2O$.cluster=as.numeric(T2O$.cluster)
ggcorr(T2O[,-1:-2,], method = c("everything", "pearson"))
cor <- cor(T2O[,-1:-2,], method = "pearson" )
cor
KT <- SD3 %>% select(5:6)
Kmeans <- kmeans(KT, 2)
Clust <- augment(Kmeans,KT)
p1 <-
ggplot(Clust, aes(x =.fittedPC1 , y =.fittedPC2)) +
geom_point(aes(color = .cluster), alpha = 0.8, size=1.5*(SD1$wx))
p1
KT <- SD3 %>% select(5:6)
Kmeans <- kmeans(KT, 3)
Clust <- augment(Kmeans,KT)
p1 <-
ggplot(Clust, aes(x =.fittedPC1 , y =.fittedPC2)) +
geom_point(aes(color = .cluster), alpha = 0.8, size=1.5*(SD1$wx))
p1
Outcomes <- read_excel("Assignment  6 Outcome data.xlsx")
T2O <- augment(Kmeans,Outcomes)
T2O$.cluster=as.numeric(T2O$.cluster)
ggcorr(T2O[,-1:-2,], method = c("everything", "pearson"))
cor <- cor(T2O[,-1:-2,], method = "pearson" )
cor
#There seems to be a moderate negative correlation between the clusters and the number of number of jumps
KT <- SD3 %>% select(5:6)
Kmeans <- kmeans(KT, 3)
Clust <- augment(Kmeans,KT)
p1 <-
ggplot(Clust, aes(x =.fittedPC1 , y =.fittedPC2)) +
geom_point(aes(color = .cluster), alpha = 0.8, size=1.5*(SD1$wx))
p1
Outcomes <- read_excel("Assignment  6 Outcome data.xlsx")
T2O <- augment(Kmeans,Outcomes)
T2O$.cluster=as.numeric(T2O$.cluster)
ggcorr(T2O[,-1:-2,], method = c("everything", "pearson"))
cor <- cor(T2O[,-1:-2,], method = "pearson" )
cor
#There seems to be a moderate negative correlation between the clusters and the number of number of jumps
KT <- SD3 %>% select(5:6)
Kmeans <- kmeans(KT, 3)
Clust <- augment(Kmeans,KT)
p1 <-
ggplot(Clust, aes(x =.fittedPC1 , y =.fittedPC2)) +
geom_point(aes(color = .cluster), alpha = 0.8, size=1.5*(SD1$wx))
p1
View(T2O)
View(T2O)
Outcomes <- read_excel("Assignment  6 Outcome data.xlsx")
T2O <- augment(Kmeans,Outcomes)
T2O$.cluster=as.numeric(T2O$.cluster)
ggcorr(T2O[,-1:-2,], method = c("everything", "pearson"))
cor <- cor(T2O[,-1:-2,], method = "pearson" )
cor
#There seems to be a moderate negative correlation between the clusters and the number of number of jumps
View(Clust)
View(Clust)
View(T2O)
View(T2O)
View(T2O)
View(T2O)
boxplot(.cluster~Jumps, data=t2O)
boxplot(.cluster~Jumps, data=T2O)
boxplot(Jumps~.cluster, data=T2O)
Outcomes <- read_excel("Assignment  6 Outcome data.xlsx")
T2O <- augment(Kmeans,Outcomes)
T2O$.cluster=as.numeric(T2O$.cluster)
ggcorr(T2O[,-1:-2,], method = c("everything", "pearson"))
cor <- cor(T2O[,-1:-2,], method = "pearson" )
cor
#There seems to be a moderate correlation (-.58) between the clusters and the number of number of jumps.
View(SD1)
View(SD1)
